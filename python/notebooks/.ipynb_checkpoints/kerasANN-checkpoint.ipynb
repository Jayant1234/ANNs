{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=7\n",
    "from numpy.random import seed\n",
    "seed(random_seed)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(random_seed)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "global varss # defining all global variables here.\n",
    "global count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8561304084881450842\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4945621811\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10575804558279978406\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#checking if GPU is used \n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_imputation(dataset): \n",
    "    \"\"\"\"\"\"\n",
    "    imputed_dataset=dataset.fillna(dataset.mean())\n",
    "    return imputed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into input (X) and output (Y)\n",
    "def splitXY(dataset): \n",
    "    \"\"\"\n",
    "    Takes numpy array as input and converts first column into Y and rest into X\n",
    "    \"\"\"\n",
    "    m,n=dataset.shape\n",
    "    Y=dataset[:,n-1]\n",
    "    X=dataset[:,0:n-1]\n",
    "    return X,Y\n",
    "\n",
    "X,Y= splitXY(dataset_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_true, y_pred):\n",
    "    \n",
    "    sse=tp.reduce_sum(tp.square(tp.subtract(y_pred,y_true)))\n",
    "    #using sst as y_true-y_mean 's squared mean\n",
    "    y_mean= tp.reduce_mean(y_true)\n",
    "    sst=tp.reduce_sum(tp.square(tp.subtract(y_true,y_mean)))\n",
    "    r_square=tp.subtract(float(1),tp.divide(sse,sst))\n",
    "    \n",
    "    \"\"\"\n",
    "    m=tp.to_float(tp.size(y_true))\n",
    "    y_true_sum_sq=(tp.square(tp.reduce_sum(y_true)))\n",
    "    y_sq_mean=tp.divide(y_true_sum_sq,m)\n",
    "    sst=tp.subtract(tp.tensordot(y_true,y_true,0),m*tp.square(tp.reduce_mean(y_true)))\n",
    "    r_square=tp.subtract(float(1),tp.divide(sse,sst))\n",
    "    \"\"\"\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_r_squared(y_true, y_pred):\n",
    "    sse=tp.reduce_sum(tp.square(tp.subtract(y_pred,y_true)))\n",
    "    #using sst as y_true-y_mean 's squared mean\n",
    "    y_mean= tp.reduce_mean(y_true)\n",
    "    sst=tp.reduce_sum(tp.square(tp.subtract(y_true,y_mean)))\n",
    "    r_square=tp.subtract(float(1),tp.divide(sse,sst))\n",
    "    \n",
    "    #n=model.count_params()#this part was working before but now is not..how to get model here though?\n",
    "    #n=sum([np.prod(K.get_value(w).shape) for w in model.trainable_weights])\n",
    "    n=tp.to_float(count)\n",
    "    #m=tp.to_float(tp.size(y_true))\n",
    "    rdf=tp.divide(tp.subtract(tp.to_float(instances),float(1)),tp.subtract(tp.to_float(instances),n))\n",
    "    r_adj_square=tp.subtract(float(1),tp.tensordot(rdf,tp.subtract(float(1),r_square),0))\n",
    "    return r_adj_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptronModel(X_dim=7,optimizer_name=\"adam\"):\n",
    "    \"\"\"Takes number of X features and activation name as input and outputs a keras model for perceptron\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=X_dim,activation=\"linear\",kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    #model.add(Dense(1,activation='linear',kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer=keras.initializers.RandomNormal(stddev=1)))\n",
    "    #model.add(Dense(1,kernel_initializer='normal'))\n",
    "    global count\n",
    "    count=model.count_params()\n",
    "    #model.add(Dense(1, input_dim=X_dim, activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer=keras.initializers.RandomNormal(stddev=1)))\n",
    "    # Compile model\n",
    "    sgd=optimizers.SGD(lr=0.05, momentum=0.05, decay=0.0, nesterov=False)\n",
    "    rmsprop=keras.optimizers.RMSprop(lr=0.05, rho=0.9, epsilon=None, decay=0.0)\n",
    "    model.compile(loss='mean_squared_error',optimizer=optimizer_name,metrics=['mse',r_squared,adj_r_squared])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetwork3LModel(X_dim,activation_name='relu',optimizer_name=\"adam\"):\n",
    "    \"\"\"Takes number of X features and activation name as input and outputs a keras model for perceptron\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7, input_dim=X_dim,activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    model.add(Dense(1,activation='linear',kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    #model.add(Dense(1,kernel_initializer='normal'))\n",
    "    \n",
    "    #model.add(Dense(1, input_dim=X_dim, activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer=keras.initializers.RandomNormal(stddev=1)))\n",
    "    # Compile model\n",
    "    global count\n",
    "    count=model.count_params()#-X_dim+1\n",
    "    sgd=optimizers.SGD(lr=0.05, momentum=0.1, decay=0.0, nesterov=False)\n",
    "    rmsprop=keras.optimizers.RMSprop(lr=0.05, rho=0.1, epsilon=None, decay=0.0)\n",
    "    model.compile(loss='mean_squared_error',optimizer=optimizer_name,metrics=['mse',r_squared,adj_r_squared])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetwork5LModel(X_dim,activation_name='relu',optimizer_name=\"adam\"):\n",
    "    \"\"\"Takes number of X features and activation name as input and outputs a keras model for perceptron\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=X_dim,activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    model.add(Dense(5,activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    model.add(Dense(5,activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    model.add(Dense(1,activation='linear',kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    #model.add(Dense(1,kernel_initializer='normal'))\n",
    "    \n",
    "    #model.add(Dense(1, input_dim=X_dim, activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer=keras.initializers.RandomNormal(stddev=1)))\n",
    "    # Compile model\n",
    "    count=model.count_params() #-3*X_dim +1\n",
    "    print('Count of parameters :'+str(count))\n",
    "    sgd=optimizers.SGD(lr=0.05, momentum=0.05, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='mean_squared_error',optimizer=optimizer_name,metrics=['mse',r_squared,adj_r_squared])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_model(X,Y,name='NeuralNetwork3L',activation_name=\"relu\",optimizer_name=\"adam\"):\n",
    "    if(len(X.shape))==1: \n",
    "        X_size=X.shape\n",
    "        X_dim=1\n",
    "    else :    \n",
    "        (X_size,X_dim)=X.shape\n",
    "    global instances\n",
    "    instances=X_size\n",
    "    if(name=='Perceptron'):\n",
    "        model =perceptronModel(X_dim,optimizer_name)\n",
    "    elif(name=='NeuralNetwork3L'):\n",
    "        model =neuralNetwork3LModel(X_dim,activation_name,optimizer_name)\n",
    "    elif(name=='NeuralNetwork5L'):\n",
    "        model =neuralNetwork5LModel(X_dim,activation_name,optimizer_name)\n",
    "    else: \n",
    "        raise Exception(\"Model Name is not correct: Please choose between given models\")\n",
    "    \n",
    "    count=model.count_params() #-3*X_dim +1\n",
    "    print('Count of parameters :'+str(count))\n",
    "    model.summary()\n",
    "    #early stopping \n",
    "    es = EarlyStopping(monitor='mean_squared_error', mode='min', verbose=1, patience=10)\n",
    "    # Fit the model\n",
    "    with tp.device('/device:GPU:0'):\n",
    "        model.fit(X, Y, epochs=4000, batch_size=50,callbacks=[es])\n",
    "        \n",
    "    return model\n",
    "#model=fit_model(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_model(X,Y,model):\n",
    "#model evaluation.\n",
    "\n",
    "    scores = model.evaluate(X, Y, verbose=0)\n",
    "        \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]*100))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]*100))\n",
    "    return scores\n",
    "#eval_model(X,Y,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find RCV value\n",
    "def cross_val_split(dataset):\n",
    "    #dataset is split into 80:20 ratio of train and test\n",
    "    np.random.shuffle(dataset)\n",
    "    m,n=dataset_np_array.shape\n",
    "    count=math.ceil(m*0.8)\n",
    "    training, test = dataset[:count,:], dataset[count:,:]\n",
    "    X_train,Y_train=splitXY(training)\n",
    "    X_test,Y_test=splitXY(test)\n",
    "#     model=fit_model(X_train,Y_train)\n",
    "#     # evaluate the model\n",
    "#     scores = eval_model(X_test,Y_test,model)\n",
    "#     r_square_cv=dict_scores[model.metrics_names[2]]=scores[2]\n",
    "    return X_train,Y_train,X_test,Y_test   \n",
    "#cross_val_split(dataset_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(dataset,modelname=\"Perceptron\",activation_name=\"relu\",optimizer_name=\"adam\"): \n",
    "    X,Y=splitXY(dataset)\n",
    "    X_train,Y_train,X_test,Y_test=cross_val_split(dataset)    \n",
    "    m,n=X.shape\n",
    "    X_cols = [] # buffer list that tells which column index is in X right now...\n",
    "    X_cols_cv=[]\n",
    "    X_set=np.empty((m,0))#for test and train with cv..this would need to be different..\n",
    "    #need to save the below values for all models calculated in for loop and only save the best sse's\n",
    "    \n",
    "    m_train,n_train=X_train.shape\n",
    "    m_test,n_test=X_test.shape\n",
    "    X_train_set=np.empty((m_train,0))\n",
    "    X_test_set=np.empty((m_test,0))\n",
    "    \n",
    "    r_square=[]\n",
    "    r_adj=[]\n",
    "    r_square_cv=[]\n",
    "    r_adj_cv=[]\n",
    "    \n",
    "    while(len(X_cols)<n):\n",
    "        sse=[]\n",
    "        sse_cv=[]\n",
    "        r_square_best=[]\n",
    "        r_adj_best=[]\n",
    "        r_square_cv_best=[]\n",
    "        r_adj_cv_best=[]\n",
    "        for i in range(0,n) :\n",
    "            if i not in X_cols :\n",
    "                #for rsq and radjsq\n",
    "                mno,nno=X_train_set.shape\n",
    "                X_train_set_copy=X_train[:,X_cols+[i]]\n",
    "                model=fit_model(X_train_set_copy,Y_train,modelname,activation_name,optimizer_name)\n",
    "            \n",
    "                X_test_set_copy=X_test[:,X_cols+[i]]\n",
    "                scores=eval_model(X_test_set_copy,Y_test,model)\n",
    "                r_square_cv_best.append(scores[2])\n",
    "                r_adj_cv_best.append(scores[3])\n",
    "                \n",
    "                scores=eval_model(X_train_set_copy,Y_train,model)\n",
    "                sse.append(float(scores[1]))\n",
    "                r_square_best.append(scores[2])\n",
    "                r_adj_best.append(scores[3])\n",
    "                \n",
    "                \n",
    "            else: \n",
    "                sse.append(math.inf)#to\n",
    "                r_square_best.append(float('-inf'))\n",
    "                r_adj_best.append(float('-inf'))                \n",
    "                r_square_cv_best.append(float('-inf'))\n",
    "                r_adj_cv_best.append(float('-inf'))\n",
    "                \n",
    "        #for rsq and radjsq\n",
    "        best_index=sse.index(min(sse))\n",
    "        X_cols.append(best_index)\n",
    "        r_square_cv.append(r_square_cv_best[best_index])\n",
    "        r_adj_cv.append(r_adj_cv_best[best_index])\n",
    "        r_square.append(r_square_best[best_index])\n",
    "        r_adj.append(r_adj_best[best_index])\n",
    "\n",
    "    return r_square,r_adj,r_square_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(datasetno,r_square,r_adj,r_square_cv,modelname):\n",
    "    m,n=dataset.shape\n",
    "    t=[i+1 for i in range(n-1)]\n",
    "    plt.plot(t,[value*100 for value in r_square], 'r--', linewidth=2.0,label=\"R-squared\")\n",
    "    plt.plot( t, [value*100 for value in r_adj], 'bs--',linewidth=2.0,label=\"R^2-adjusted\")\n",
    "    plt.plot( t,[value*100 for value in r_square_cv],'g^--',linewidth=2.0,label=\"Rcv-square\")\n",
    "    plt.xlabel(\"n:Forward Selection\")\n",
    "    plt.ylabel(\"R square values\")\n",
    "    plt.legend()\n",
    "    x=str(datasetno)\n",
    "    if not os.path.exists('../../plots/'+x):\n",
    "        os.makedirs('../../plots/'+x)\n",
    "    plt.savefig('../../plots/'+x+'/'+modelname+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment manual script\n",
    "dataset = pd.read_csv(\"../../data/1.csv\", delimiter=\",\")\n",
    "dataset=mean_imputation(dataset)\n",
    "dataset_np_array=dataset.values\n",
    "X,Y=splitXY(dataset_np_array)\n",
    "model=fit_model(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of parameters :22\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_438 (Dense)            (None, 7)                 14        \n",
      "_________________________________________________________________\n",
      "dense_439 (Dense)            (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 22\n",
      "Trainable params: 22\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#running script\n",
    "activations_exp=['sigmoid','relu','linear','tanh']\n",
    "optimizer_exp=['sgd','adam','rmsprop','adagrad']\n",
    "modelnames=[\"NeuralNetwork3L\",\"NeuralNetwork5L\"]\n",
    "\n",
    "\n",
    "for datasetno in range(9,-1,-1): \n",
    "    for modelname in modelnames: \n",
    "        datasetname=datasetno+1\n",
    "        dataset = pd.read_csv(\"../../data/\"+str(datasetname)+\".csv\", delimiter=\",\")\n",
    "        dataset=mean_imputation(dataset)\n",
    "        dataset_np_array=dataset.values\n",
    "        r_square,r_adj,r_square_cv=forward_selection(dataset_np_array,modelname,\"relu\",\"adam\")\n",
    "        save_plots(datasetno+1,r_square,r_adj,r_square_cv,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
