{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=7\n",
    "from numpy.random import seed\n",
    "seed(random_seed)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(random_seed)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "global varss # defining all global variables here.\n",
    "global count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8561304084881450842\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4945621811\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10575804558279978406\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#checking if GPU is used \n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_imputation(dataset): \n",
    "    \"\"\"\"\"\"\n",
    "    imputed_dataset=dataset.fillna(dataset.mean())\n",
    "    return imputed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into input (X) and output (Y)\n",
    "def splitXY(dataset): \n",
    "    \"\"\"\n",
    "    Takes numpy array as input and converts first column into Y and rest into X\n",
    "    \"\"\"\n",
    "    m,n=dataset.shape\n",
    "    Y=dataset[:,n-1]\n",
    "    X=dataset[:,0:n-1]\n",
    "    return X,Y\n",
    "\n",
    "X,Y= splitXY(dataset_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_true, y_pred):\n",
    "    \n",
    "    sse=tp.reduce_sum(tp.square(tp.subtract(y_pred,y_true)))\n",
    "    #using sst as y_true-y_mean 's squared mean\n",
    "    y_mean= tp.reduce_mean(y_true)\n",
    "    sst=tp.reduce_sum(tp.square(tp.subtract(y_true,y_mean)))\n",
    "    r_square=tp.subtract(float(1),tp.divide(sse,sst))\n",
    "    \n",
    "    \"\"\"\n",
    "    m=tp.to_float(tp.size(y_true))\n",
    "    y_true_sum_sq=(tp.square(tp.reduce_sum(y_true)))\n",
    "    y_sq_mean=tp.divide(y_true_sum_sq,m)\n",
    "    sst=tp.subtract(tp.tensordot(y_true,y_true,0),m*tp.square(tp.reduce_mean(y_true)))\n",
    "    r_square=tp.subtract(float(1),tp.divide(sse,sst))\n",
    "    \"\"\"\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_r_squared(y_true, y_pred):\n",
    "    sse=tp.reduce_sum(tp.square(tp.subtract(y_pred,y_true)))\n",
    "    #using sst as y_true-y_mean 's squared mean\n",
    "    y_mean= tp.reduce_mean(y_true)\n",
    "    sst=tp.reduce_sum(tp.square(tp.subtract(y_true,y_mean)))\n",
    "    r_square=tp.subtract(float(1),tp.divide(sse,sst))\n",
    "    \n",
    "    #n=model.count_params()#this part was working before but now is not..how to get model here though?\n",
    "    #n=sum([np.prod(K.get_value(w).shape) for w in model.trainable_weights])\n",
    "    n=tp.to_float(count)\n",
    "    #m=tp.to_float(tp.size(y_true))\n",
    "    rdf=tp.divide(tp.subtract(tp.to_float(instances),float(1)),tp.subtract(tp.to_float(instances),n))\n",
    "    r_adj_square=tp.subtract(float(1),tp.tensordot(rdf,tp.subtract(float(1),r_square),0))\n",
    "    return r_adj_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptronModel(X_dim=7,optimizer_name=\"adam\"):\n",
    "    \"\"\"Takes number of X features and activation name as input and outputs a keras model for perceptron\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=X_dim,activation=\"linear\",kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    #model.add(Dense(1,activation='linear',kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer=keras.initializers.RandomNormal(stddev=1)))\n",
    "    #model.add(Dense(1,kernel_initializer='normal'))\n",
    "    global count\n",
    "    count=model.count_params()\n",
    "    #model.add(Dense(1, input_dim=X_dim, activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer=keras.initializers.RandomNormal(stddev=1)))\n",
    "    # Compile model\n",
    "    sgd=optimizers.SGD(lr=0.05, momentum=0.05, decay=0.0, nesterov=False)\n",
    "    rmsprop=keras.optimizers.RMSprop(lr=0.05, rho=0.9, epsilon=None, decay=0.0)\n",
    "    model.compile(loss='mean_squared_error',optimizer=optimizer_name,metrics=['mse',r_squared,adj_r_squared])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetwork3LModel(X_dim,activation_name='relu',optimizer_name=\"adam\"):\n",
    "    \"\"\"Takes number of X features and activation name as input and outputs a keras model for perceptron\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7, input_dim=X_dim,activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    model.add(Dense(1,activation='linear',kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    #model.add(Dense(1,kernel_initializer='normal'))\n",
    "    \n",
    "    #model.add(Dense(1, input_dim=X_dim, activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer=keras.initializers.RandomNormal(stddev=1)))\n",
    "    # Compile model\n",
    "    global count\n",
    "    count=model.count_params()#-X_dim+1\n",
    "    sgd=optimizers.SGD(lr=0.05, momentum=0.1, decay=0.0, nesterov=False)\n",
    "    rmsprop=keras.optimizers.RMSprop(lr=0.05, rho=0.1, epsilon=None, decay=0.0)\n",
    "    model.compile(loss='mean_squared_error',optimizer=optimizer_name,metrics=['mse',r_squared,adj_r_squared])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetwork5LModel(X_dim,activation_name='relu',optimizer_name=\"adam\"):\n",
    "    \"\"\"Takes number of X features and activation name as input and outputs a keras model for perceptron\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=X_dim,activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    model.add(Dense(5,activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    model.add(Dense(5,activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    model.add(Dense(1,activation='linear',kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer='zeros'))\n",
    "    #model.add(Dense(1,kernel_initializer='normal'))\n",
    "    \n",
    "    #model.add(Dense(1, input_dim=X_dim, activation=activation_name,kernel_initializer=keras.initializers.RandomNormal(stddev=1),bias_initializer=keras.initializers.RandomNormal(stddev=1)))\n",
    "    # Compile model\n",
    "    count=model.count_params() #-3*X_dim +1\n",
    "    print('Count of parameters :'+str(count))\n",
    "    sgd=optimizers.SGD(lr=0.05, momentum=0.05, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='mean_squared_error',optimizer=optimizer_name,metrics=['mse',r_squared,adj_r_squared])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_model(X,Y,name='NeuralNetwork3L',activation_name=\"relu\",optimizer_name=\"adam\"):\n",
    "    if(len(X.shape))==1: \n",
    "        X_size=X.shape\n",
    "        X_dim=1\n",
    "    else :    \n",
    "        (X_size,X_dim)=X.shape\n",
    "    global instances\n",
    "    instances=X_size\n",
    "    if(name=='Perceptron'):\n",
    "        model =perceptronModel(X_dim,optimizer_name)\n",
    "    elif(name=='NeuralNetwork3L'):\n",
    "        model =neuralNetwork3LModel(X_dim,activation_name,optimizer_name)\n",
    "    elif(name=='NeuralNetwork5L'):\n",
    "        model =neuralNetwork5LModel(X_dim,activation_name,optimizer_name)\n",
    "    else: \n",
    "        raise Exception(\"Model Name is not correct: Please choose between given models\")\n",
    "    \n",
    "    count=model.count_params() #-3*X_dim +1\n",
    "    print('Count of parameters :'+str(count))\n",
    "    model.summary()\n",
    "    #early stopping \n",
    "    es = EarlyStopping(monitor='mean_squared_error', mode='min', verbose=1, patience=10)\n",
    "    # Fit the model\n",
    "    with tp.device('/device:GPU:0'):\n",
    "        model.fit(X, Y, epochs=4000, batch_size=50,callbacks=[es])\n",
    "        \n",
    "    return model\n",
    "#model=fit_model(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_model(X,Y,model):\n",
    "#model evaluation.\n",
    "\n",
    "    scores = model.evaluate(X, Y, verbose=0)\n",
    "        \n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[2], scores[2]*100))\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[3], scores[3]*100))\n",
    "    return scores\n",
    "#eval_model(X,Y,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find RCV value\n",
    "def cross_val_split(dataset):\n",
    "    #dataset is split into 80:20 ratio of train and test\n",
    "    np.random.shuffle(dataset)\n",
    "    m,n=dataset_np_array.shape\n",
    "    count=math.ceil(m*0.8)\n",
    "    training, test = dataset[:count,:], dataset[count:,:]\n",
    "    X_train,Y_train=splitXY(training)\n",
    "    X_test,Y_test=splitXY(test)\n",
    "#     model=fit_model(X_train,Y_train)\n",
    "#     # evaluate the model\n",
    "#     scores = eval_model(X_test,Y_test,model)\n",
    "#     r_square_cv=dict_scores[model.metrics_names[2]]=scores[2]\n",
    "    return X_train,Y_train,X_test,Y_test   \n",
    "#cross_val_split(dataset_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(dataset,modelname=\"Perceptron\",activation_name=\"relu\",optimizer_name=\"adam\"): \n",
    "    X,Y=splitXY(dataset)\n",
    "    X_train,Y_train,X_test,Y_test=cross_val_split(dataset)    \n",
    "    m,n=X.shape\n",
    "    X_cols = [] # buffer list that tells which column index is in X right now...\n",
    "    X_cols_cv=[]\n",
    "    X_set=np.empty((m,0))#for test and train with cv..this would need to be different..\n",
    "    #need to save the below values for all models calculated in for loop and only save the best sse's\n",
    "    \n",
    "    m_train,n_train=X_train.shape\n",
    "    m_test,n_test=X_test.shape\n",
    "    X_train_set=np.empty((m_train,0))\n",
    "    X_test_set=np.empty((m_test,0))\n",
    "    \n",
    "    r_square=[]\n",
    "    r_adj=[]\n",
    "    r_square_cv=[]\n",
    "    r_adj_cv=[]\n",
    "    \n",
    "    while(len(X_cols)<n):\n",
    "        sse=[]\n",
    "        sse_cv=[]\n",
    "        r_square_best=[]\n",
    "        r_adj_best=[]\n",
    "        r_square_cv_best=[]\n",
    "        r_adj_cv_best=[]\n",
    "        for i in range(0,n) :\n",
    "            if i not in X_cols :\n",
    "                #for rsq and radjsq\n",
    "                mno,nno=X_train_set.shape\n",
    "                X_train_set_copy=X_train[:,X_cols+[i]]\n",
    "                model=fit_model(X_train_set_copy,Y_train,modelname,activation_name,optimizer_name)\n",
    "            \n",
    "                X_test_set_copy=X_test[:,X_cols+[i]]\n",
    "                scores=eval_model(X_test_set_copy,Y_test,model)\n",
    "                r_square_cv_best.append(scores[2])\n",
    "                r_adj_cv_best.append(scores[3])\n",
    "                \n",
    "                scores=eval_model(X_train_set_copy,Y_train,model)\n",
    "                sse.append(float(scores[1]))\n",
    "                r_square_best.append(scores[2])\n",
    "                r_adj_best.append(scores[3])\n",
    "                \n",
    "                \n",
    "            else: \n",
    "                sse.append(math.inf)#to\n",
    "                r_square_best.append(float('-inf'))\n",
    "                r_adj_best.append(float('-inf'))                \n",
    "                r_square_cv_best.append(float('-inf'))\n",
    "                r_adj_cv_best.append(float('-inf'))\n",
    "                \n",
    "        #for rsq and radjsq\n",
    "        best_index=sse.index(min(sse))\n",
    "        X_cols.append(best_index)\n",
    "        r_square_cv.append(r_square_cv_best[best_index])\n",
    "        r_adj_cv.append(r_adj_cv_best[best_index])\n",
    "        r_square.append(r_square_best[best_index])\n",
    "        r_adj.append(r_adj_best[best_index])\n",
    "\n",
    "    return r_square,r_adj,r_square_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(datasetno,r_square,r_adj,r_square_cv,modelname):\n",
    "    m,n=dataset.shape\n",
    "    t=[i+1 for i in range(n-1)]\n",
    "    plt.plot(t,[value*100 for value in r_square], 'r--', linewidth=2.0,label=\"R-squared\")\n",
    "    plt.plot( t, [value*100 for value in r_adj], 'bs--',linewidth=2.0,label=\"R^2-adjusted\")\n",
    "    plt.plot( t,[value*100 for value in r_square_cv],'g^--',linewidth=2.0,label=\"Rcv-square\")\n",
    "    plt.xlabel(\"n:Forward Selection\")\n",
    "    plt.ylabel(\"R square values\")\n",
    "    plt.legend()\n",
    "    x=str(datasetno)\n",
    "    if not os.path.exists('../../plots/'+x):\n",
    "        os.makedirs('../../plots/'+x)\n",
    "    plt.savefig('../../plots/'+x+'/'+modelname+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment manual script\n",
    "dataset = pd.read_csv(\"../../data/1.csv\", delimiter=\",\")\n",
    "dataset=mean_imputation(dataset)\n",
    "dataset_np_array=dataset.values\n",
    "X,Y=splitXY(dataset_np_array)\n",
    "model=fit_model(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of parameters :22\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_438 (Dense)            (None, 7)                 14        \n",
      "_________________________________________________________________\n",
      "dense_439 (Dense)            (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 22\n",
      "Trainable params: 22\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4000\n",
      "247/247 [==============================] - 3s 14ms/sample - loss: 351.9777 - mean_squared_error: 351.9778 - r_squared: -0.5392 - adj_r_squared: -0.6828\n",
      "Epoch 2/4000\n",
      "247/247 [==============================] - 0s 208us/sample - loss: 350.8668 - mean_squared_error: 350.8669 - r_squared: -0.5105 - adj_r_squared: -0.6515\n",
      "Epoch 3/4000\n",
      "247/247 [==============================] - 0s 204us/sample - loss: 349.6849 - mean_squared_error: 349.6849 - r_squared: -0.5065 - adj_r_squared: -0.6472\n",
      "Epoch 4/4000\n",
      "247/247 [==============================] - 0s 217us/sample - loss: 348.5867 - mean_squared_error: 348.5867 - r_squared: -0.4904 - adj_r_squared: -0.6295\n",
      "Epoch 5/4000\n",
      "247/247 [==============================] - 0s 267us/sample - loss: 347.4343 - mean_squared_error: 347.4343 - r_squared: -0.4788 - adj_r_squared: -0.6168\n",
      "Epoch 6/4000\n",
      "247/247 [==============================] - 0s 211us/sample - loss: 346.3462 - mean_squared_error: 346.3462 - r_squared: -0.4816 - adj_r_squared: -0.6199\n",
      "Epoch 7/4000\n",
      "247/247 [==============================] - 0s 200us/sample - loss: 345.2573 - mean_squared_error: 345.2573 - r_squared: -0.4968 - adj_r_squared: -0.6365\n",
      "Epoch 8/4000\n",
      "247/247 [==============================] - 0s 288us/sample - loss: 344.1339 - mean_squared_error: 344.1339 - r_squared: -0.4667 - adj_r_squared: -0.6036\n",
      "Epoch 9/4000\n",
      "247/247 [==============================] - 0s 214us/sample - loss: 343.0911 - mean_squared_error: 343.0911 - r_squared: -0.4668 - adj_r_squared: -0.6037\n",
      "Epoch 10/4000\n",
      "247/247 [==============================] - 0s 237us/sample - loss: 342.2006 - mean_squared_error: 342.2006 - r_squared: -0.4663 - adj_r_squared: -0.6032\n",
      "Epoch 11/4000\n",
      "247/247 [==============================] - 0s 260us/sample - loss: 341.3179 - mean_squared_error: 341.3179 - r_squared: -0.4672 - adj_r_squared: -0.6041\n",
      "Epoch 12/4000\n",
      "247/247 [==============================] - 0s 296us/sample - loss: 340.4392 - mean_squared_error: 340.4391 - r_squared: -0.4640 - adj_r_squared: -0.6006\n",
      "Epoch 13/4000\n",
      "247/247 [==============================] - 0s 268us/sample - loss: 339.5502 - mean_squared_error: 339.5502 - r_squared: -0.4482 - adj_r_squared: -0.5833\n",
      "Epoch 14/4000\n",
      "247/247 [==============================] - 0s 220us/sample - loss: 338.7030 - mean_squared_error: 338.7030 - r_squared: -0.4393 - adj_r_squared: -0.5736\n",
      "Epoch 15/4000\n",
      "247/247 [==============================] - 0s 205us/sample - loss: 337.8152 - mean_squared_error: 337.8152 - r_squared: -0.4374 - adj_r_squared: -0.5716\n",
      "Epoch 16/4000\n",
      "247/247 [==============================] - 0s 229us/sample - loss: 336.9718 - mean_squared_error: 336.9718 - r_squared: -0.4408 - adj_r_squared: -0.5753\n",
      "Epoch 17/4000\n",
      "247/247 [==============================] - 0s 238us/sample - loss: 336.1536 - mean_squared_error: 336.1537 - r_squared: -0.4332 - adj_r_squared: -0.5669\n",
      "Epoch 18/4000\n",
      "247/247 [==============================] - 0s 216us/sample - loss: 335.3373 - mean_squared_error: 335.3373 - r_squared: -0.4395 - adj_r_squared: -0.5739\n",
      "Epoch 19/4000\n",
      "247/247 [==============================] - 0s 202us/sample - loss: 334.4682 - mean_squared_error: 334.4681 - r_squared: -0.4302 - adj_r_squared: -0.5637\n",
      "Epoch 20/4000\n",
      "247/247 [==============================] - 0s 268us/sample - loss: 333.5906 - mean_squared_error: 333.5905 - r_squared: -0.4232 - adj_r_squared: -0.5560\n",
      "Epoch 21/4000\n",
      "247/247 [==============================] - 0s 209us/sample - loss: 332.8389 - mean_squared_error: 332.8389 - r_squared: -0.4351 - adj_r_squared: -0.5690\n",
      "Epoch 22/4000\n",
      "247/247 [==============================] - 0s 263us/sample - loss: 331.9935 - mean_squared_error: 331.9935 - r_squared: -0.4092 - adj_r_squared: -0.5407\n",
      "Epoch 23/4000\n",
      "247/247 [==============================] - 0s 214us/sample - loss: 331.1922 - mean_squared_error: 331.1922 - r_squared: -0.4173 - adj_r_squared: -0.5496\n",
      "Epoch 24/4000\n",
      "247/247 [==============================] - 0s 202us/sample - loss: 330.4005 - mean_squared_error: 330.4005 - r_squared: -0.4055 - adj_r_squared: -0.5367\n",
      "Epoch 25/4000\n",
      "247/247 [==============================] - 0s 270us/sample - loss: 329.5541 - mean_squared_error: 329.5541 - r_squared: -0.4050 - adj_r_squared: -0.5361\n",
      "Epoch 26/4000\n",
      "247/247 [==============================] - 0s 234us/sample - loss: 328.7702 - mean_squared_error: 328.7702 - r_squared: -0.4071 - adj_r_squared: -0.5384\n",
      "Epoch 27/4000\n",
      "247/247 [==============================] - 0s 276us/sample - loss: 328.0058 - mean_squared_error: 328.0059 - r_squared: -0.3931 - adj_r_squared: -0.5231\n",
      "Epoch 28/4000\n",
      "247/247 [==============================] - 0s 205us/sample - loss: 327.1913 - mean_squared_error: 327.1913 - r_squared: -0.4187 - adj_r_squared: -0.5511\n",
      "Epoch 29/4000\n",
      "247/247 [==============================] - 0s 242us/sample - loss: 326.4492 - mean_squared_error: 326.4492 - r_squared: -0.3869 - adj_r_squared: -0.5164\n",
      "Epoch 30/4000\n",
      "247/247 [==============================] - 0s 261us/sample - loss: 325.6334 - mean_squared_error: 325.6334 - r_squared: -0.3884 - adj_r_squared: -0.5180\n",
      "Epoch 31/4000\n",
      "247/247 [==============================] - 0s 214us/sample - loss: 324.8956 - mean_squared_error: 324.8956 - r_squared: -0.3886 - adj_r_squared: -0.5182\n",
      "Epoch 32/4000\n",
      "247/247 [==============================] - 0s 241us/sample - loss: 324.1435 - mean_squared_error: 324.1435 - r_squared: -0.3960 - adj_r_squared: -0.5262\n",
      "Epoch 33/4000\n",
      "247/247 [==============================] - 0s 270us/sample - loss: 323.4010 - mean_squared_error: 323.4010 - r_squared: -0.3785 - adj_r_squared: -0.5072\n",
      "Epoch 34/4000\n",
      "247/247 [==============================] - 0s 208us/sample - loss: 322.6236 - mean_squared_error: 322.6236 - r_squared: -0.3706 - adj_r_squared: -0.4985\n",
      "Epoch 35/4000\n",
      "247/247 [==============================] - 0s 264us/sample - loss: 321.8891 - mean_squared_error: 321.8891 - r_squared: -0.3735 - adj_r_squared: -0.5017\n",
      "Epoch 36/4000\n",
      "247/247 [==============================] - 0s 242us/sample - loss: 321.1218 - mean_squared_error: 321.1218 - r_squared: -0.3804 - adj_r_squared: -0.5092\n",
      "Epoch 37/4000\n",
      "247/247 [==============================] - 0s 241us/sample - loss: 320.3925 - mean_squared_error: 320.3925 - r_squared: -0.3620 - adj_r_squared: -0.4892\n",
      "Epoch 38/4000\n",
      "247/247 [==============================] - 0s 260us/sample - loss: 319.6434 - mean_squared_error: 319.6434 - r_squared: -0.3691 - adj_r_squared: -0.4968\n",
      "Epoch 39/4000\n",
      "247/247 [==============================] - 0s 294us/sample - loss: 318.9980 - mean_squared_error: 318.9980 - r_squared: -0.3704 - adj_r_squared: -0.4983\n",
      "Epoch 40/4000\n",
      "247/247 [==============================] - 0s 217us/sample - loss: 318.1909 - mean_squared_error: 318.1909 - r_squared: -0.3595 - adj_r_squared: -0.4864\n",
      "Epoch 41/4000\n",
      "247/247 [==============================] - 0s 211us/sample - loss: 317.4936 - mean_squared_error: 317.4936 - r_squared: -0.3487 - adj_r_squared: -0.4746\n",
      "Epoch 42/4000\n",
      "247/247 [==============================] - 0s 207us/sample - loss: 316.8468 - mean_squared_error: 316.8469 - r_squared: -0.3500 - adj_r_squared: -0.4760\n",
      "Epoch 43/4000\n",
      "247/247 [==============================] - 0s 250us/sample - loss: 316.1015 - mean_squared_error: 316.1015 - r_squared: -0.3548 - adj_r_squared: -0.4812\n",
      "Epoch 44/4000\n",
      "247/247 [==============================] - 0s 303us/sample - loss: 315.4135 - mean_squared_error: 315.4135 - r_squared: -0.3457 - adj_r_squared: -0.4713\n",
      "Epoch 45/4000\n",
      "247/247 [==============================] - 0s 307us/sample - loss: 314.7240 - mean_squared_error: 314.7241 - r_squared: -0.3357 - adj_r_squared: -0.4603\n",
      "Epoch 46/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 0s 234us/sample - loss: 314.0112 - mean_squared_error: 314.0112 - r_squared: -0.3401 - adj_r_squared: -0.4652\n",
      "Epoch 47/4000\n",
      "247/247 [==============================] - 0s 215us/sample - loss: 313.4025 - mean_squared_error: 313.4025 - r_squared: -0.3453 - adj_r_squared: -0.4708\n",
      "Epoch 48/4000\n",
      "247/247 [==============================] - 0s 275us/sample - loss: 312.6688 - mean_squared_error: 312.6688 - r_squared: -0.3390 - adj_r_squared: -0.4640\n",
      "Epoch 49/4000\n",
      "247/247 [==============================] - 0s 230us/sample - loss: 311.9821 - mean_squared_error: 311.9821 - r_squared: -0.3240 - adj_r_squared: -0.4476\n",
      "Epoch 50/4000\n",
      "247/247 [==============================] - 0s 260us/sample - loss: 311.3197 - mean_squared_error: 311.3196 - r_squared: -0.3328 - adj_r_squared: -0.4572\n",
      "Epoch 51/4000\n",
      "247/247 [==============================] - 0s 218us/sample - loss: 310.6679 - mean_squared_error: 310.6679 - r_squared: -0.3212 - adj_r_squared: -0.4445\n",
      "Epoch 52/4000\n",
      "247/247 [==============================] - 0s 265us/sample - loss: 310.0265 - mean_squared_error: 310.0265 - r_squared: -0.3273 - adj_r_squared: -0.4512\n",
      "Epoch 53/4000\n",
      "247/247 [==============================] - 0s 201us/sample - loss: 309.3596 - mean_squared_error: 309.3596 - r_squared: -0.3195 - adj_r_squared: -0.4427\n",
      "Epoch 54/4000\n",
      "247/247 [==============================] - 0s 230us/sample - loss: 308.7650 - mean_squared_error: 308.7650 - r_squared: -0.3166 - adj_r_squared: -0.4395\n",
      "Epoch 55/4000\n",
      "247/247 [==============================] - 0s 211us/sample - loss: 308.0388 - mean_squared_error: 308.0388 - r_squared: -0.3191 - adj_r_squared: -0.4422\n",
      "Epoch 56/4000\n",
      "247/247 [==============================] - 0s 262us/sample - loss: 307.4423 - mean_squared_error: 307.4424 - r_squared: -0.3123 - adj_r_squared: -0.4348\n",
      "Epoch 57/4000\n",
      "247/247 [==============================] - 0s 199us/sample - loss: 306.8120 - mean_squared_error: 306.8120 - r_squared: -0.3130 - adj_r_squared: -0.4356\n",
      "Epoch 58/4000\n",
      "247/247 [==============================] - 0s 226us/sample - loss: 306.1362 - mean_squared_error: 306.1362 - r_squared: -0.3075 - adj_r_squared: -0.4295\n",
      "Epoch 59/4000\n",
      "247/247 [==============================] - 0s 200us/sample - loss: 305.5598 - mean_squared_error: 305.5598 - r_squared: -0.2989 - adj_r_squared: -0.4202\n",
      "Epoch 60/4000\n",
      "247/247 [==============================] - 0s 252us/sample - loss: 304.9363 - mean_squared_error: 304.9363 - r_squared: -0.3047 - adj_r_squared: -0.4265\n",
      "Epoch 61/4000\n",
      "247/247 [==============================] - 0s 270us/sample - loss: 304.3839 - mean_squared_error: 304.3839 - r_squared: -0.3183 - adj_r_squared: -0.4414\n",
      "Epoch 62/4000\n",
      "247/247 [==============================] - 0s 216us/sample - loss: 303.6882 - mean_squared_error: 303.6882 - r_squared: -0.2973 - adj_r_squared: -0.4183\n",
      "Epoch 63/4000\n",
      "247/247 [==============================] - 0s 215us/sample - loss: 303.0900 - mean_squared_error: 303.0900 - r_squared: -0.2996 - adj_r_squared: -0.4209\n",
      "Epoch 64/4000\n",
      "247/247 [==============================] - 0s 206us/sample - loss: 302.5391 - mean_squared_error: 302.5391 - r_squared: -0.3003 - adj_r_squared: -0.4216\n",
      "Epoch 65/4000\n",
      "247/247 [==============================] - 0s 240us/sample - loss: 301.8844 - mean_squared_error: 301.8844 - r_squared: -0.2902 - adj_r_squared: -0.4106\n",
      "Epoch 66/4000\n",
      "247/247 [==============================] - 0s 203us/sample - loss: 301.2918 - mean_squared_error: 301.2918 - r_squared: -0.2878 - adj_r_squared: -0.4080\n",
      "Epoch 67/4000\n",
      "247/247 [==============================] - 0s 250us/sample - loss: 300.7631 - mean_squared_error: 300.7631 - r_squared: -0.2702 - adj_r_squared: -0.3888\n",
      "Epoch 68/4000\n",
      "247/247 [==============================] - 0s 270us/sample - loss: 300.1846 - mean_squared_error: 300.1846 - r_squared: -0.2842 - adj_r_squared: -0.4040\n",
      "Epoch 69/4000\n",
      "247/247 [==============================] - 0s 199us/sample - loss: 299.5972 - mean_squared_error: 299.5972 - r_squared: -0.2780 - adj_r_squared: -0.3973\n",
      "Epoch 70/4000\n",
      "247/247 [==============================] - 0s 253us/sample - loss: 298.9946 - mean_squared_error: 298.9946 - r_squared: -0.2830 - adj_r_squared: -0.4027\n",
      "Epoch 71/4000\n",
      "247/247 [==============================] - 0s 272us/sample - loss: 298.4278 - mean_squared_error: 298.4278 - r_squared: -0.2653 - adj_r_squared: -0.3833\n",
      "Epoch 72/4000\n",
      "247/247 [==============================] - 0s 207us/sample - loss: 297.8640 - mean_squared_error: 297.8640 - r_squared: -0.2636 - adj_r_squared: -0.3815\n",
      "Epoch 73/4000\n",
      "247/247 [==============================] - 0s 203us/sample - loss: 297.3801 - mean_squared_error: 297.3801 - r_squared: -0.2646 - adj_r_squared: -0.3826\n",
      "Epoch 74/4000\n",
      "247/247 [==============================] - 0s 208us/sample - loss: 296.7611 - mean_squared_error: 296.7611 - r_squared: -0.2748 - adj_r_squared: -0.3938\n",
      "Epoch 75/4000\n",
      "247/247 [==============================] - 0s 222us/sample - loss: 296.2098 - mean_squared_error: 296.2098 - r_squared: -0.2635 - adj_r_squared: -0.3815\n",
      "Epoch 76/4000\n",
      "247/247 [==============================] - 0s 214us/sample - loss: 295.6861 - mean_squared_error: 295.6861 - r_squared: -0.2595 - adj_r_squared: -0.3771\n",
      "Epoch 77/4000\n",
      "247/247 [==============================] - 0s 266us/sample - loss: 295.1679 - mean_squared_error: 295.1679 - r_squared: -0.2514 - adj_r_squared: -0.3682\n",
      "Epoch 78/4000\n",
      "247/247 [==============================] - 0s 212us/sample - loss: 294.6213 - mean_squared_error: 294.6213 - r_squared: -0.2762 - adj_r_squared: -0.3953\n",
      "Epoch 79/4000\n",
      "247/247 [==============================] - 0s 220us/sample - loss: 294.0848 - mean_squared_error: 294.0849 - r_squared: -0.2598 - adj_r_squared: -0.3774\n",
      "Epoch 80/4000\n",
      "247/247 [==============================] - 0s 216us/sample - loss: 293.5217 - mean_squared_error: 293.5217 - r_squared: -0.2492 - adj_r_squared: -0.3658\n",
      "Epoch 81/4000\n",
      "247/247 [==============================] - 0s 245us/sample - loss: 293.0084 - mean_squared_error: 293.0085 - r_squared: -0.2538 - adj_r_squared: -0.3709\n",
      "Epoch 82/4000\n",
      "247/247 [==============================] - 0s 220us/sample - loss: 292.5124 - mean_squared_error: 292.5124 - r_squared: -0.2526 - adj_r_squared: -0.3696\n",
      "Epoch 83/4000\n",
      "247/247 [==============================] - 0s 216us/sample - loss: 292.0643 - mean_squared_error: 292.0643 - r_squared: -0.2593 - adj_r_squared: -0.3768\n",
      "Epoch 84/4000\n",
      "247/247 [==============================] - 0s 250us/sample - loss: 291.4692 - mean_squared_error: 291.4692 - r_squared: -0.2415 - adj_r_squared: -0.3573\n",
      "Epoch 85/4000\n",
      "247/247 [==============================] - 0s 272us/sample - loss: 290.9721 - mean_squared_error: 290.9721 - r_squared: -0.2403 - adj_r_squared: -0.3560\n",
      "Epoch 86/4000\n",
      "247/247 [==============================] - 0s 205us/sample - loss: 290.4903 - mean_squared_error: 290.4903 - r_squared: -0.2320 - adj_r_squared: -0.3469\n",
      "Epoch 87/4000\n",
      "247/247 [==============================] - 0s 234us/sample - loss: 290.0152 - mean_squared_error: 290.0153 - r_squared: -0.2386 - adj_r_squared: -0.3542\n",
      "Epoch 88/4000\n",
      "247/247 [==============================] - 0s 201us/sample - loss: 289.5107 - mean_squared_error: 289.5107 - r_squared: -0.2325 - adj_r_squared: -0.3476\n",
      "Epoch 89/4000\n",
      "247/247 [==============================] - 0s 249us/sample - loss: 289.0539 - mean_squared_error: 289.0540 - r_squared: -0.2318 - adj_r_squared: -0.3468\n",
      "Epoch 90/4000\n",
      "247/247 [==============================] - 0s 266us/sample - loss: 288.5646 - mean_squared_error: 288.5646 - r_squared: -0.2334 - adj_r_squared: -0.3485\n",
      "Epoch 91/4000\n",
      "247/247 [==============================] - 0s 210us/sample - loss: 288.0588 - mean_squared_error: 288.0588 - r_squared: -0.2322 - adj_r_squared: -0.3473\n",
      "Epoch 92/4000\n",
      "247/247 [==============================] - 0s 223us/sample - loss: 287.5670 - mean_squared_error: 287.5669 - r_squared: -0.2327 - adj_r_squared: -0.3478\n",
      "Epoch 93/4000\n",
      "247/247 [==============================] - 0s 201us/sample - loss: 287.1744 - mean_squared_error: 287.1744 - r_squared: -0.2215 - adj_r_squared: -0.3355\n",
      "Epoch 94/4000\n",
      "247/247 [==============================] - 0s 239us/sample - loss: 286.6619 - mean_squared_error: 286.6619 - r_squared: -0.2183 - adj_r_squared: -0.3320\n",
      "Epoch 95/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 0s 224us/sample - loss: 286.2731 - mean_squared_error: 286.2732 - r_squared: -0.2257 - adj_r_squared: -0.3400\n",
      "Epoch 96/4000\n",
      "247/247 [==============================] - 0s 187us/sample - loss: 285.7650 - mean_squared_error: 285.7650 - r_squared: -0.2196 - adj_r_squared: -0.3334\n",
      "Epoch 97/4000\n",
      "247/247 [==============================] - 0s 239us/sample - loss: 285.3367 - mean_squared_error: 285.3367 - r_squared: -0.2122 - adj_r_squared: -0.3254\n",
      "Epoch 98/4000\n",
      "247/247 [==============================] - 0s 238us/sample - loss: 284.8830 - mean_squared_error: 284.8830 - r_squared: -0.2097 - adj_r_squared: -0.3226\n",
      "Epoch 99/4000\n",
      "247/247 [==============================] - 0s 207us/sample - loss: 284.4250 - mean_squared_error: 284.4250 - r_squared: -0.2104 - adj_r_squared: -0.3233\n",
      "Epoch 100/4000\n",
      "247/247 [==============================] - 0s 238us/sample - loss: 284.0084 - mean_squared_error: 284.0085 - r_squared: -0.2048 - adj_r_squared: -0.3172\n",
      "Epoch 101/4000\n",
      "247/247 [==============================] - 0s 254us/sample - loss: 283.6040 - mean_squared_error: 283.6040 - r_squared: -0.2048 - adj_r_squared: -0.3173\n",
      "Epoch 102/4000\n",
      "247/247 [==============================] - 0s 220us/sample - loss: 283.1606 - mean_squared_error: 283.1606 - r_squared: -0.2160 - adj_r_squared: -0.3295\n",
      "Epoch 103/4000\n",
      "247/247 [==============================] - 0s 210us/sample - loss: 282.7447 - mean_squared_error: 282.7446 - r_squared: -0.2028 - adj_r_squared: -0.3151\n",
      "Epoch 104/4000\n",
      "247/247 [==============================] - 0s 203us/sample - loss: 282.3216 - mean_squared_error: 282.3216 - r_squared: -0.2021 - adj_r_squared: -0.3143\n",
      "Epoch 105/4000\n",
      "247/247 [==============================] - 0s 224us/sample - loss: 281.9181 - mean_squared_error: 281.9181 - r_squared: -0.1960 - adj_r_squared: -0.3076\n"
     ]
    }
   ],
   "source": [
    "#running script\n",
    "activations_exp=['sigmoid','relu','linear','tanh']\n",
    "optimizer_exp=['sgd','adam','rmsprop','adagrad']\n",
    "modelnames=[\"NeuralNetwork3L\",\"NeuralNetwork5L\"]\n",
    "\n",
    "\n",
    "for datasetno in range(9,-1,-1): \n",
    "    for modelname in modelnames: \n",
    "        datasetname=datasetno+1\n",
    "        dataset = pd.read_csv(\"../../data/\"+str(datasetname)+\".csv\", delimiter=\",\")\n",
    "        dataset=mean_imputation(dataset)\n",
    "        dataset_np_array=dataset.values\n",
    "        r_square,r_adj,r_square_cv=forward_selection(dataset_np_array,modelname,\"relu\",\"adam\")\n",
    "        save_plots(datasetno+1,r_square,r_adj,r_square_cv,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
